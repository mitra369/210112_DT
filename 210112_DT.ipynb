# GitHub URL for Wine dataset
GITHUB_RAW_URL = "https://raw.githubusercontent.com/mitra369/DT_210112/main/wine.csv"

# Drive path (if needed as backup)
DRIVE_PATH = "/content/drive/MyDrive/wine.csv"
import pandas as pd
import os

df = None
if GITHUB_RAW_URL:
    try:
        df = pd.read_csv("https://raw.githubusercontent.com/mitra369/DT_210112/main/wine.csv")
        print("Loaded Wine dataset from GitHub raw URL.")
    except Exception as e:
        print("Failed to load from GitHub URL:", e)

if df is None:
    from google.colab import drive
    drive.mount('/content/drive')
    if os.path.exists(DRIVE_PATH):
        df = pd.read_csv(DRIVE_PATH)
        print("Loaded Wine dataset from Google Drive.")
    else:
        raise FileNotFoundError(f"Could not find file at GitHub or Drive. Please verify GITHUB_RAW_URL or DRIVE_PATH: {DRIVE_PATH}")

print("Shape:", df.shape)
print("Expected shape: (178, 14) - 178 samples, 13 features + 1 target column")
df.head()
print("Columns:", df.columns.tolist())
print("\nDtypes:\n", df.dtypes)
print("\nNull counts:\n", df.isnull().sum())
print("\nValue counts for target column:")

for c in ['class', 'Class', 'Wine', 'target', 'label', 'cultivar']:
    if c in df.columns:
        print(f"\n{c}:\n", df[c].value_counts(dropna=False).sort_index())

display(df.describe().T)
df.columns = [c.strip() for c in df.columns]

df = df.loc[:, ~df.columns.str.contains("^Unnamed")]

possible_targets = ['class', 'Class', 'Wine', 'target', 'label', 'cultivar', 'Type']
target_col = None
for t in possible_targets:
    if t in df.columns:
        target_col = t
        break

if target_col is None:
    raise ValueError("Could not find a target column automatically. Rename the target column to 'class' or 'target' and re-run.")

print("Detected target column:", target_col)


if df[target_col].dtype == object:
    df[target_col] = pd.to_numeric(df[target_col], errors='coerce')
    print("Converted target column to numeric")

print(f"Target classes: {sorted(df[target_col].unique())}")
print(f"Class distribution:\n{df[target_col].value_counts().sort_index()}")

for id_col in ['id', 'ID', 'Id', 'sample_id']:
    if id_col in df.columns:
        df = df.drop(columns=[id_col])
        print(f"Dropped column: {id_col}")

print("Final columns:", df.columns.tolist())
print(f"Final shape: {df.shape}")
from sklearn.model_selection import train_test_split

X = df.drop(columns=[target_col])
y = df[target_col]

print(f"Features shape: {X.shape}")
print(f"Target shape: {y.shape}")
print(f"Feature columns: {X.columns.tolist()}")

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42, stratify=y
)

print("\nData split complete:")
print(f"Train: {X_train.shape} ({len(X_train)/len(X)*100:.1f}%)")
print(f"Test: {X_test.shape} ({len(X_test)/len(X)*100:.1f}%)")

print(f"\nTrain class distribution:\n{y_train.value_counts().sort_index()}")
print(f"\nTest class distribution:\n{y_test.value_counts().sort_index()}")
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder

num_cols = X_train.select_dtypes(include=['int64','float64','int32','float32']).columns.tolist()
cat_cols = X_train.select_dtypes(include=['object','category','bool']).columns.tolist()

print("Numeric cols:", num_cols)
print(f"Number of numeric features: {len(num_cols)}")
print("Categorical cols:", cat_cols)
print(f"Number of categorical features: {len(cat_cols)}")

num_imputer = SimpleImputer(strategy='median')

X_train_num = X_train[num_cols].copy()
X_test_num = X_test[num_cols].copy()

X_train_num_imp = pd.DataFrame(num_imputer.fit_transform(X_train_num), columns=num_cols, index=X_train_num.index)
X_test_num_imp = pd.DataFrame(num_imputer.transform(X_test_num), columns=num_cols, index=X_test_num.index)

print(f"\nMissing values after imputation - Train: {X_train_num_imp.isnull().sum().sum()}")

print("\n‚úì Decision Trees don't require scaling (unlike KNN)")

if cat_cols:
    from sklearn.preprocessing import LabelEncoder
    X_train_cat = X_train[cat_cols].copy()
    X_test_cat = X_test[cat_cols].copy()

    for col in cat_cols:
        le = LabelEncoder()
        X_train_cat[col] = le.fit_transform(X_train_cat[col].astype(str))
        X_test_cat[col] = le.transform(X_test_cat[col].astype(str))

    X_train_proc = pd.concat([X_train_num_imp, X_train_cat], axis=1)
    X_test_proc = pd.concat([X_test_num_imp, X_test_cat], axis=1)
else:
    X_train_proc = X_train_num_imp
    X_test_proc = X_test_num_imp

print(f"\nProcessed shapes:")
print(f"Train: {X_train_proc.shape}")
print(f"Test: {X_test_proc.shape}")
print(f"\nAll 13 chemical features are preprocessed and ready for Decision Trees!")

display(X_train_proc.head())
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

print("=" * 60)
print("TRAINING CART MODEL (Gini Criterion)")
print("=" * 60)

cart_model = DecisionTreeClassifier(criterion='gini', random_state=42)

param_grid_cart = {
    'max_depth': [3, 5, 7, 9, 11, 15, 20, None],
    'min_samples_split': [2, 5, 10, 15, 20],
    'min_samples_leaf': [1, 2, 4, 6]
}

print(f"Total combinations to test: {len(param_grid_cart['max_depth']) * len(param_grid_cart['min_samples_split']) * len(param_grid_cart['min_samples_leaf'])}")
print("Starting GridSearchCV for CART (Gini)...\n")

grid_cart = GridSearchCV(
    cart_model,
    param_grid_cart,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)

grid_cart.fit(X_train_proc, y_train)

print("\n" + "=" * 60)
print("CART GridSearchCV Complete!")
print("=" * 60)
print("Best parameters for CART (Gini):")
for param, value in grid_cart.best_params_.items():
    print(f"  {param}: {value}")
print(f"\nBest Cross-Validation Accuracy: {grid_cart.best_score_:.4f}")
print("=" * 60)

best_cart = grid_cart.best_estimator_

y_test_pred_cart = best_cart.predict(X_test_proc)
y_test_prob_cart = best_cart.predict_proba(X_test_proc)

print("\nCART (Gini) - Test Set Performance:")
print("=" * 60)
print(f"Accuracy:            {accuracy_score(y_test, y_test_pred_cart):.4f}")
print(f"Precision (weighted): {precision_score(y_test, y_test_pred_cart, average='weighted'):.4f}")
print(f"Recall (weighted):    {recall_score(y_test, y_test_pred_cart, average='weighted'):.4f}")
print(f"F1-Score (weighted):  {f1_score(y_test, y_test_pred_cart, average='weighted'):.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_test_pred_cart, target_names=['Class 0', 'Class 1', 'Class 2']))
print("\n" + "=" * 60)
print("TRAINING ID3 MODEL (Entropy Criterion)")
print("=" * 60)

id3_model = DecisionTreeClassifier(criterion='entropy', random_state=42)

param_grid_id3 = {
    'max_depth': [3, 5, 7, 9, 11, 15, 20, None],
    'min_samples_split': [2, 5, 10, 15, 20],
    'min_samples_leaf': [1, 2, 4, 6]
}

print(f"Total combinations to test: {len(param_grid_id3['max_depth']) * len(param_grid_id3['min_samples_split']) * len(param_grid_id3['min_samples_leaf'])}")
print("Starting GridSearchCV for ID3 (Entropy)...\n")

grid_id3 = GridSearchCV(
    id3_model,
    param_grid_id3,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)

grid_id3.fit(X_train_proc, y_train)

print("\n" + "=" * 60)
print("ID3 GridSearchCV Complete!")
print("=" * 60)
print("Best parameters for ID3 (Entropy):")
for param, value in grid_id3.best_params_.items():
    print(f"  {param}: {value}")
print(f"\nBest Cross-Validation Accuracy: {grid_id3.best_score_:.4f}")
print("=" * 60)

best_id3 = grid_id3.best_estimator_

y_test_pred_id3 = best_id3.predict(X_test_proc)
y_test_prob_id3 = best_id3.predict_proba(X_test_proc)

print("\nID3 (Entropy) - Test Set Performance:")
print("=" * 60)
print(f"Accuracy:            {accuracy_score(y_test, y_test_pred_id3):.4f}")
print(f"Precision (weighted): {precision_score(y_test, y_test_pred_id3, average='weighted'):.4f}")
print(f"Recall (weighted):    {recall_score(y_test, y_test_pred_id3, average='weighted'):.4f}")
print(f"F1-Score (weighted):  {f1_score(y_test, y_test_pred_id3, average='weighted'):.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_test_pred_id3, target_names=['Class 0', 'Class 1', 'Class 2'])
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm_cart = confusion_matrix(y_test, y_test_pred_cart)
cm_id3 = confusion_matrix(y_test, y_test_pred_id3)

fig, axes = plt.subplots(1, 2, figsize=(14, 6))

sns.heatmap(cm_cart, annot=True, fmt='d', cmap='Blues', linewidths=0.5,
            xticklabels=['Class 0', 'Class 1', 'Class 2'],
            yticklabels=['Class 0', 'Class 1', 'Class 2'],
            cbar_kws={'label': 'Count'}, ax=axes[0])
axes[0].set_title('CART (Gini) - Confusion Matrix', fontsize=14, fontweight='bold')
axes[0].set_xlabel('Predicted Label', fontsize=12)
axes[0].set_ylabel('True Label', fontsize=12)

sns.heatmap(cm_id3, annot=True, fmt='d', cmap='Greens', linewidths=0.5,
            xticklabels=['Class 0', 'Class 1', 'Class 2'],
            yticklabels=['Class 0', 'Class 1', 'Class 2'],
            cbar_kws={'label': 'Count'}, ax=axes[1])
axes[1].set_title('ID3 (Entropy) - Confusion Matrix', fontsize=14, fontweight='bold')
axes[1].set_xlabel('Predicted Label', fontsize=12)
axes[1].set_ylabel('True Label', fontsize=12)

plt.tight_layout()
plt.show()

print("=" * 60)
print("Confusion Matrix Comparison:")
print(f"CART Total Correct: {cm_cart.trace()}/{y_test.shape[0]}")
print(f"ID3 Total Correct: {cm_id3.trace()}/{y_test.shape[0]}")
print("=" * 60)
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
import numpy as np

n_classes = 3
y_test_bin = label_binarize(y_test, classes=[0, 1, 2])

fig, axes = plt.subplots(1, 2, figsize=(16, 6))

fpr_cart = dict()
tpr_cart = dict()
roc_auc_cart = dict()

for i in range(n_classes):
    fpr_cart[i], tpr_cart[i], _ = roc_curve(y_test_bin[:, i], y_test_prob_cart[:, i])
    roc_auc_cart[i] = auc(fpr_cart[i], tpr_cart[i])
    axes[0].plot(fpr_cart[i], tpr_cart[i], linewidth=2.5,
                 label=f'Class {i} (AUC = {roc_auc_cart[i]:.3f})')

axes[0].plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random (AUC = 0.500)')
axes[0].set_xlim([0.0, 1.0])
axes[0].set_ylim([0.0, 1.05])
axes[0].set_xlabel('False Positive Rate', fontsize=12)
axes[0].set_ylabel('True Positive Rate', fontsize=12)
axes[0].set_title('CART (Gini) - ROC Curves', fontsize=14, fontweight='bold')
axes[0].legend(loc="lower right", fontsize=10)
axes[0].grid(True, alpha=0.3)

fpr_id3 = dict()
tpr_id3 = dict()
roc_auc_id3 = dict()

for i in range(n_classes):
    fpr_id3[i], tpr_id3[i], _ = roc_curve(y_test_bin[:, i], y_test_prob_id3[:, i])
    roc_auc_id3[i] = auc(fpr_id3[i], tpr_id3[i])
    axes[1].plot(fpr_id3[i], tpr_id3[i], linewidth=2.5,
                 label=f'Class {i} (AUC = {roc_auc_id3[i]:.3f})')

axes[1].plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random (AUC = 0.500)')
axes[1].set_xlim([0.0, 1.0])
axes[1].set_ylim([0.0, 1.05])
axes[1].set_xlabel('False Positive Rate', fontsize=12)
axes[1].set_ylabel('True Positive Rate', fontsize=12)
axes[1].set_title('ID3 (Entropy) - ROC Curves', fontsize=14, fontweight='bold')
axes[1].legend(loc="lower right", fontsize=10)
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("=" * 60)
print("ROC AUC Comparison:")
print("=" * 60)
print("CART (Gini) - AUC per class:")
for i in range(n_classes):
    print(f"  Class {i}: {roc_auc_cart[i]:.4f}")
print(f"  Average: {np.mean(list(roc_auc_cart.values())):.4f}")

print("\nID3 (Entropy) - AUC per class:")
for i in range(n_classes):
    print(f"  Class {i}: {roc_auc_id3[i]:.4f}")
print(f"  Average: {np.mean(list(roc_auc_id3.values())):.4f}")
print("=" * 60)
from sklearn.metrics import roc_auc_score
import numpy as np

metrics = {
    'Accuracy': [
        accuracy_score(y_test, y_test_pred_cart),
        accuracy_score(y_test, y_test_pred_id3)
    ],
    'Precision': [
        precision_score(y_test, y_test_pred_cart, average='weighted'),
        precision_score(y_test, y_test_pred_id3, average='weighted')
    ],
    'Recall': [
        recall_score(y_test, y_test_pred_cart, average='weighted'),
        recall_score(y_test, y_test_pred_id3, average='weighted')
    ],
    'F1-Score': [
        f1_score(y_test, y_test_pred_cart, average='weighted'),
        f1_score(y_test, y_test_pred_id3, average='weighted')
    ],
    'AUC': [
        roc_auc_score(y_test, y_test_prob_cart, multi_class='ovr', average='weighted'),
        roc_auc_score(y_test, y_test_prob_id3, multi_class='ovr', average='weighted')
    ]
}

metric_names = list(metrics.keys())
cart_scores = [metrics[m][0] for m in metric_names]
id3_scores = [metrics[m][1] for m in metric_names]

x = np.arange(len(metric_names))
width = 0.35

fig, ax = plt.subplots(figsize=(12, 7))
bars1 = ax.bar(x - width/2, cart_scores, width, label='CART (Gini)', color='#3498db', edgecolor='black', linewidth=1.5)
bars2 = ax.bar(x + width/2, id3_scores, width, label='ID3 (Entropy)', color='#2ecc71', edgecolor='black', linewidth=1.5)

for bars in [bars1, bars2]:
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.3f}',
                ha='center', va='bottom', fontsize=10, fontweight='bold')

ax.set_xlabel('Metrics', fontsize=13, fontweight='bold')
ax.set_ylabel('Score', fontsize=13, fontweight='bold')
ax.set_title('CART vs ID3 - Performance Comparison (Wine Dataset)', fontsize=15, fontweight='bold')
ax.set_xticks(x)
ax.set_xticklabels(metric_names, fontsize=11)
ax.set_ylim([0, 1.1])
ax.legend(fontsize=12, loc='lower right')
ax.grid(axis='y', alpha=0.3, linestyle='--')

plt.tight_layout()
plt.show()

print("\n" + "=" * 60)
print("CART vs ID3 - Metrics Comparison Table")
print("=" * 60)
print(f"{'Metric':<15} {'CART (Gini)':<15} {'ID3 (Entropy)':<15} {'Difference':<15}")
print("-" * 60)
for metric in metric_names:
    cart_val = metrics[metric][0]
    id3_val = metrics[metric][1]
    diff = cart_val - id3_val
    print(f"{metric:<15} {cart_val:<15.4f} {id3_val:<15.4f} {diff:>+14.4f}")
print("=" * 60)

cart_avg = np.mean(cart_scores)
id3_avg = np.mean(id3_scores)
print(f"\nAverage Score - CART: {cart_avg:.4f} | ID3: {id3_avg:.4f}")
if cart_avg > id3_avg:
    print(f"üèÜ Winner: CART (Gini) by {(cart_avg - id3_avg):.4f}")
elif id3_avg > cart_avg:
    print(f"üèÜ Winner: ID3 (Entropy) by {(id3_avg - cart_avg):.4f}")
else:
    print("ü§ù Tie! Both models perform equally well")
print("=" * 60)
from sklearn.decomposition import PCA
import numpy as np

print("Creating 2D Decision Boundary Visualization...")
print("=" * 60)

pca = PCA(n_components=2, random_state=42)
X_train_pca = pca.fit_transform(X_train_proc)
X_test_pca = pca.transform(X_test_proc)

print(f"PCA Explained Variance Ratio: {pca.explained_variance_ratio_}")
print(f"Total Variance Explained: {sum(pca.explained_variance_ratio_):.2%}")

cart_pca = DecisionTreeClassifier(
    criterion='gini',
    max_depth=best_cart.max_depth,
    min_samples_split=best_cart.min_samples_split,
    min_samples_leaf=best_cart.min_samples_leaf,
    random_state=42
)
cart_pca.fit(X_train_pca, y_train)

id3_pca = DecisionTreeClassifier(
    criterion='entropy',
    max_depth=best_id3.max_depth,
    min_samples_split=best_id3.min_samples_split,
    min_samples_leaf=best_id3.min_samples_leaf,
    random_state=42
)
id3_pca.fit(X_train_pca, y_train)

x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1
y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1
xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300), np.linspace(y_min, y_max, 300))
grid = np.c_[xx.ravel(), yy.ravel()]

Z_cart = cart_pca.predict(grid).reshape(xx.shape)
Z_id3 = id3_pca.predict(grid).reshape(xx.shape)

fig, axes = plt.subplots(1, 2, figsize=(16, 7))

colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
cmap = plt.matplotlib.colors.ListedColormap(colors)

axes[0].contourf(xx, yy, Z_cart, alpha=0.4, cmap=cmap, levels=[-.5, 0.5, 1.5, 2.5])
scatter0 = axes[0].scatter(X_test_pca[:, 0], X_test_pca[:, 1],
                          c=y_test, cmap=cmap,
                          edgecolor='black', s=100, linewidth=1.5)
axes[0].set_title(f'CART (Gini) - Decision Boundary\n' +
                 f'max_depth={best_cart.max_depth}, min_samples_split={best_cart.min_samples_split}',
                 fontsize=13, fontweight='bold')
axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)', fontsize=11)
axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)', fontsize=11)
axes[0].grid(True, alpha=0.3)

axes[1].contourf(xx, yy, Z_id3, alpha=0.4, cmap=cmap, levels=[-.5, 0.5, 1.5, 2.5])
scatter1 = axes[1].scatter(X_test_pca[:, 0], X_test_pca[:, 1],
                          c=y_test, cmap=cmap,
                          edgecolor='black', s=100, linewidth=1.5)
axes[1].set_title(f'ID3 (Entropy) - Decision Boundary\n' +
                 f'max_depth={best_id3.max_depth}, min_samples_split={best_id3.min_samples_split}',
                 fontsize=13, fontweight='bold')
axes[1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)', fontsize=11)
axes[1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)', fontsize=11)
axes[1].grid(True, alpha=0.3)

cbar = fig.colorbar(scatter1, ax=axes, ticks=[0, 1, 2], orientation='vertical', pad=0.02)
cbar.set_label('Wine Class', fontsize=12)
cbar.ax.set_yticklabels(['Class 0', 'Class 1', 'Class 2'])

plt.tight_layout()
plt.show()

print("\nDecision Boundary Visualization Complete!")
print("=" * 60)
from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

print("=" * 60)
print("VISUALIZING DECISION TREE STRUCTURES")
print("=" * 60)

feature_names = X_train_proc.columns.tolist()
class_names = ['Class 0', 'Class 1', 'Class 2']

fig, axes = plt.subplots(1, 2, figsize=(24, 10))

plot_tree(best_cart,
          feature_names=feature_names,
          class_names=class_names,
          filled=True,
          rounded=True,
          fontsize=9,
          ax=axes[0])
axes[0].set_title(f'CART (Gini) - Tree Structure\n' +
                 f'Depth={best_cart.get_depth()}, Nodes={best_cart.tree_.node_count}, ' +
                 f'Leaves={best_cart.get_n_leaves()}',
                 fontsize=14, fontweight='bold', pad=20)

plot_tree(best_id3,
          feature_names=feature_names,
          class_names=class_names,
          filled=True,
          rounded=True,
          fontsize=9,
          ax=axes[1])
axes[1].set_title(f'ID3 (Entropy) - Tree Structure\n' +
                 f'Depth={best_id3.get_depth()}, Nodes={best_id3.tree_.node_count}, ' +
                 f'Leaves={best_id3.get_n_leaves()}',
                 fontsize=14, fontweight='bold', pad=20)

plt.tight_layout()
plt.show()

print("\nTree Structure Comparison:")
print("=" * 60)
print(f"{'Metric':<25} {'CART (Gini)':<20} {'ID3 (Entropy)':<20}")
print("-" * 60)
print(f"{'Max Depth (param)':<25} {best_cart.max_depth if best_cart.max_depth else 'None':<20} {best_id3.max_depth if best_id3.max_depth else 'None':<20}")
print(f"{'Actual Depth':<25} {best_cart.get_depth():<20} {best_id3.get_depth():<20}")
print(f"{'Total Nodes':<25} {best_cart.tree_.node_count:<20} {best_id3.tree_.node_count:<20}")
print(f"{'Leaf Nodes':<25} {best_cart.get_n_leaves():<20} {best_id3.get_n_leaves():<20}")
print(f"{'Min Samples Split':<25} {best_cart.min_samples_split:<20} {best_id3.min_samples_split:<20}")
print(f"{'Min Samples Leaf':<25} {best_cart.min_samples_leaf:<20} {best_id3.min_samples_leaf:<20}")
print("=" * 60)

print("\nüìå Creating detailed single tree visualizations...")

plt.figure(figsize=(20, 12))
plot_tree(best_cart,
          feature_names=feature_names,
          class_names=class_names,
          filled=True,
          rounded=True,
          fontsize=10)
plt.title(f'CART (Gini) - Detailed Tree Structure (Wine Dataset)',
          fontsize=16, fontweight='bold', pad=20)
plt.tight_layout()
plt.show()

plt.figure(figsize=(20, 12))
plot_tree(best_id3,
          feature_names=feature_names,
          class_names=class_names,
          filled=True,
          rounded=True,
          fontsize=10)
plt.title(f'ID3 (Entropy) - Detailed Tree Structure (Wine Dataset)',
          fontsize=16, fontweight='bold', pad=20)
plt.tight_layout()
plt.show()

print("\n‚úÖ Tree structure visualizations complete!")
print("=" * 60)
import joblib


cart_filename = "cart_wine_model.pkl"
id3_filename = "id3_wine_model.pkl"

joblib.dump(best_cart, cart_filename)
joblib.dump(best_id3, id3_filename)

print("=" * 60)
print("MODELS SAVED SUCCESSFULLY!")
print("=" * 60)
print(f"CART Model: {cart_filename}")
print(f"ID3 Model:  {id3_filename}")
print("\nBoth models contain optimized hyperparameters from GridSearchCV")

print("\n" + "=" * 60)
print("FINAL SUMMARY - CART vs ID3 on Wine Dataset")
print("=" * 60)

print("\nüîµ CART (Gini) Best Parameters:")
print(f"  ‚Ä¢ max_depth: {best_cart.max_depth}")
print(f"  ‚Ä¢ min_samples_split: {best_cart.min_samples_split}")
print(f"  ‚Ä¢ min_samples_leaf: {best_cart.min_samples_leaf}")
print(f"  ‚Ä¢ Tree Depth: {best_cart.get_depth()}")
print(f"  ‚Ä¢ Total Nodes: {best_cart.tree_.node_count}")
print(f"  ‚Ä¢ Leaf Nodes: {best_cart.get_n_leaves()}")
print(f"  ‚Ä¢ Test Accuracy: {accuracy_score(y_test, y_test_pred_cart):.4f}")

print("\nüü¢ ID3 (Entropy) Best Parameters:")
print(f"  ‚Ä¢ max_depth: {best_id3.max_depth}")
print(f"  ‚Ä¢ min_samples_split: {best_id3.min_samples_split}")
print(f"  ‚Ä¢ min_samples_leaf: {best_id3.min_samples_leaf}")
print(f"  ‚Ä¢ Tree Depth: {best_id3.get_depth()}")
print(f"  ‚Ä¢ Total Nodes: {best_id3.tree_.node_count}")
print(f"  ‚Ä¢ Leaf Nodes: {best_id3.get_n_leaves()}")
print(f"  ‚Ä¢ Test Accuracy: {accuracy_score(y_test, y_test_pred_id3):.4f}")

print("\n" + "=" * 60)
print("SUBMISSION CHECKLIST:")
print("=" * 60)
print("Upload to GitHub (https://github.com/mitra369/DT_210112):")
print("  [ ] wine.csv (dataset)")
print("  [ ] DT_Wine_Assignment.ipynb (this notebook)")
print("  [ ] cart_wine_model.pkl (CART model)")
print("  [ ] id3_wine_model.pkl (ID3 model)")
print("  [ ] README.md (optional)")
print("\nMake sure your repository is PUBLIC!")
print("\n‚úÖ Assignment Requirements:")
print("  [‚úì] GitHub repository created")
print("  [‚úì] Automatic dataset loading from GitHub")
print("  [‚úì] Data preprocessing (imputation, encoding)")
print("  [‚úì] CART (Gini) with hyperparameter tuning")
print("  [‚úì] ID3 (Entropy) with hyperparameter tuning")
print("  [‚úì] Confusion Matrix (2x1 comparison)")
print("  [‚úì] ROC Curves (2x1 comparison)")
print("  [‚úì] Decision Boundary (2x1 comparison)")
print("  [‚úì] Metrics Bar Chart (combined)")
print("  [‚úì] Tree Structure Visualization")
print("=" * 60)
print("\nüéâ ALL REQUIREMENTS COMPLETED!")
print("=" * 60)
